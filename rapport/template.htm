<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="fr">
<head>
	<title>On Spectral Clustering: Analysis and an algorithm</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="stylesheet" href="./style.css" type="text/css">
	<meta name="KeyWords" content="ISIMA, TP, imagerie">
	<meta name="Description" content="Compte-rendu de projet de TP d'Algorithmes pour le traitement d'images">
</head>

<body>
	<h1>On Spectral Clustering: Analysis and an algorithm</h1>
	<h3>Benoît Garçon & Pierre-Loup Pissavy, PROMO 17 F2</h3>
	<h1 class="titrearticle"> Présentation du sujet </h1>
	<p>
		Ce rapport a été rédigé dans le cadre d’un cours d’algorithmes pour le traitement d'image délivré par V. Barra et C. Tilmant, suivi à l’Institut Supérieur d’Informatique, de Modélisation et de leurs Applications (ISIMA). Il a pour but de présenter succinctement nos travaux sur le programme de clustering d'images basé sur de l'analyse spectrale. Ce document est un complément du programme implémenté en C++ et dont les aspects sont abordés plus loin.
	</p>
	<p>
		Au cours de ce projet d'imagerie nous avons donc réussi à développer un programme paramétrable permettant d'extraire dans une image N ensembles de points ou zones à similarité élevée. Ce programme se base sur les travaux d'Andrew Y. Ng, Michael I. Jordan et Yair Weiss sur le clustering spectral en 2002 <strong><a href="#biblio-1">[1]</a></strong>.
	</p>
	<p>
		L'idée générale de leur algorithme est assez simple : le coeur du travail consiste à partitionner l'image avec un algorithme classique des K-Means mais au lieu de baser la classification directement sur les paramètres des points, on effectue d'abord une analyse spectrale des points. Ainsi on s'abstrait d'un côté de l'espace des paramètres et on peut détecter des zones dites <strong>non-convexes</strong> là où un simple K-Means se limiterait à des formes convexes.
	</p>
	<p>
		Nous présenterons tout d’abord l’algorithme, son principe et les détails de son implémentation. Ensuite nous exposerons les différents résultats obtenus grâce au programme produit. Enfin nous discuterons des différents résultats par rapport aux objectifs initiaux.
	</p>
	<br/>
	<h1 class="titrearticle"> Méthode</h1>


	<h2 class="soustitrearticle"> Partie théorique</h2>
	<p>
		Présentation de la méthode utilisée et référence aux travaux connexes (cf. biblio article)

		<ol class="algo">
			<h3><li>
				Préparation des données 
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Calcul de la matrice d'affinité A
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Calcul de la matrice d'analyse L
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Extraction des k vecteurs propres ayant les plus grandes valeurs propres
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Renormalisation de la matrice des k vecteurs propres
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Application d'un algorithme de clustering sur la matrice des vecteurs propres
			</li></h3>
			<p>
				
			</p>
			<h3><li>
				Assignement des points au cluster de leur ligne de la matrice des vecteurs propres
			</li></h3>
			<p>
				
			</p>
		</ol>
	</p>
	<h2 class="soustitrearticle"> Implémentation</h2>
	<p>
		Nous allons maintenant aborder les détails d'implémentation de notre programme. Celui-ci se présente sous la forme d'un code C++ utilisant la bibliothèque CImg pour le traitement des images. Son utilisation est assez simple :
	</p>	
	<ul>
		<em>spectral_clustering [ input_image [ nb_classes [ sigma ] ] ]</em> avec
		<li>
			<strong>input_image</strong> : le chemin vers l'image à traiter
		</li>
		<li>
			<strong>nb_classes</strong> : le nombre de classes k que l'on veut obtenir
		</li>
		<li>
			<strong>sigma</strong> : le paramètre de controle de la plongée de la matrice d'affinité
		</li>
	</ul>
	<p>
		Le code source se décompose en trois classes très liées mais qui permettent une grande modularité du code :
	</p>
	<ul>
		<li>
			<strong>ClusteringAlgorithm</strong> : cette classe abstraite propose une interface générique de clustering et permet de modulariser le code pour pouvoir facilement interchanger les algorithmes avec des foncteurs.
		</li>
		<li>
			<strong>SpectralAlgorithm</strong> : cette classe implémente sa classe mère ClusteringAlgorithm avec l'algorithme vu précédemment. L'algorithme de classement de l'étape 5 peut être modifié grâce au polymorphisme du foncteur utilisé.
		</li>
		<li>
			<strong>KMeans</strong> : cette classe implémente sa classe mère ClusteringAlgorithm avec l'algorithme des K-Means.
		</li>
	</ul>
	<p>
		<ol class="algo">
			<h3><li>
				Préparation des données 
			</li></h3>
			<p>
				A partir de l'image source, on extrait les attributs: la <strong>moyenne</strong> et la <strong>variance</strong>. On réalise ce travail avec un masque 3x3. Il s'agit d'un masque de petite taille. Ce choix se justifie par la quantité de mémoire nécessaire dans la suite du programme (cf. <a href="#discussion">Discussion</a>). En effet, nous avons dû utiliser des images de petite taille afin de pouvoir travailler en temps raisonnable.
				Les valeurs obtenues sont ensuite normalisées pour faciliter le paramétrage de sigma.
			</p>
			<h3><li>
				Calcul de la matrice d'affinité A
			</li></h3>
			<p>
				Le calcul de la matrice d'affinité répond à la formule proposée plus haut. Il s'agit donc d'une matrice de distances définissant la proximité entre les attributs associés à chaque pixel. Cette matrice est normalisée.<br/>

				Ce travail est réalisé par la méthode <code>SpectralClustering::GetAffinityMatrix()</code>.

			</p>
			<h3><li>
				Calcul de la matrice d'analyse L
			</li></h3>
			<p>
				Cette étape se décompose en deux phases. La première consiste à déterminer la matrice diagonale D où chaque élément de la diagonale correspond à la somme des éléments de la ligne correspondante de la matrice d'affinité. Ensuite, on construit la matrice d'analyse L comme étant D<sup>-1/2</sup>AD<sup>-1/2</sup>. L est normalisée.<br/>

				Ce travail est réalisé par les méthodes <code>SpectralClustering::GetDSqrtInvMatrix()</code> et <code>SpectralClustering::GetLMatrix()</code>.
			</p>
			<h3><li>
				Extraction des k vecteurs propres ayant les plus grandes valeurs propres
			</li></h3>
			<p>
				Pour réaliser cette étape, nous utilisons la bibliothèque CImg. On obtient alors les valeurs et vecteurs propres triés, il suffit de conserver les k premiers vecteurs. <br/>

				La matrice contenant ces vecteurs est normalisée.<br/>

				Ce travail est réalisé en 2 lignes dans la méthode <code>SpectralClustering::GetEigenMatrix()</code>.
			</p>
			<h3><li>
				Renormalisation de la matrice des k vecteurs propres
			</li></h3>
			<p>
				La matrice des k vecteurs propres est normalisée pour que chaque ligne soit un vecteur de longueur unitaire. <br/>

				Ce travail est obtenu par la méthode <code>SpectralClustering::GetNormalizedEigenMatrix()</code>.
			</p>
			<h3><li>
				Application d'un algorithme de clustering sur la matrice des vecteurs propres
			</li></h3>
			<p>
				Chaque ligne de la matrice est considérée comme un jeu de paramètres. Lorsque deux lignes se ressemblent, elles sont associées au même cluster.<br/>
				Dans notre implémentation, nous avons employé l'algorithme des K-Means pour réaliser ces regroupements.
			</p>
			<h3><li>
				Assignement des points au cluster de leur ligne dans la matrice des vecteurs propres
			</li></h3>
			<p>
				A partir des associations de l'étape précédente, les données représentées par chaque ligne sont clusterisées dans le cluster associé à la ligne. <br/>

				Cette partie est obtenue par lecture des résultats précédents dans <code>SpectralClustering::GetFinalClusteringImage()</code>.
			</p>
		</ol>
	</p>
	<br/>
	<h1 class="titrearticle">Résultats</h1>

	<h2 class="soustitrearticle">Validation sur données de synthèse</h2>
	<p>
		Nous avons créé des images pour réaliser nos tests:
	</p>
	<table>
	<tbody>
		<tr>
			<td><div class="image">
				<img src="../tests/test1.bmp" alt="test1.bmp"/>
				<span class="legende">test1.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test2.bmp" alt="test2.bmp"/>
				<span class="legende">test2.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test3.bmp" alt="test3.bmp"/>
				<span class="legende">test3.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test4.bmp" alt="test4.bmp"/>
				<span class="legende">test4.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test5.bmp" alt="test5.bmp"/>
				<span class="legende">test5.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test6.bmp" alt="test6.bmp"/>
				<span class="legende">test6.bmp</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/test7.bmp" alt="test7.bmp"/>
				<span class="legende">test7.bmp</span>
			</div></td>
		</tr>
	</tbody>
	</table>
	</p>
	<p>
		Ces tests nous ont permis d'obtenir les résultats suivants:
	</p>
	<table>
	<thead><tr><th></th><th colspan="7"></th></tr></thead>
	<tbody>
		<tr>
			<td>2 clusters</td>
			<td><div class="image">
				<img src="../tests/2/test1.bmp_res.bmp" alt="test1.bmp"/>
				<span class="legende">test1.bmp<br/>sigma=25.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test2_c2_s06_res.bmp" alt="test2.bmp"/>
				<span class="legende">test2.bmp<br/>sigma=6.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test3.bmp_res.bmp" alt="test3.bmp"/>
				<span class="legende">test3.bmp<br/>sigma=25.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test4_c2_s03_res.bmp" alt="test4.bmp"/>
				<span class="legende">test4.bmp<br/>sigma=3.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test5.bmp_res.bmp" alt="test5.bmp"/>
				<span class="legende">test5.bmp<br/>sigma=25.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test6.bmp_res.bmp" alt="test6.bmp"/>
				<span class="legende">test6.bmp<br/>sigma=25.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/2/test7.bmp_res.bmp" alt="test7.bmp"/>
				<span class="legende">test7.bmp<br/>sigma=25.0</span>
			</div></td>
		</tr>
		<tr>
			<td>3 clusters</td>
			<td></td>
			<td></td>
			<td></td>
			<td></td>
			<td><div class="image">
				<img src="../tests/3/test5_c3_s18_res.bmp" alt="test5.bmp"/>
				<span class="legende">test5.bmp<br/>sigma=18.0</span>
			</div></td>
			<td><div class="image">
				<img src="../tests/3/test6_c3_s18_res.bmp" alt="test6.bmp"/>
				<span class="legende">test6.bmp<br/>sigma=18.0</span>
			</div></td>
			<td></td>
		</tr>
	</tbody>
	</table>
	
	<h2 class="soustitrearticle">Données réelles</h2>
	<p class="TODO">
		Une fois la méthode évaluée, vous appliquerez votre méthode sur des images réelles.
	</p>
	<br/>
	<h1 class="titrearticle" id="discussion">Discussion</h1>
	<p>
		Comme on peut le voir dans la section précédente, les résultats sont plutôt concordant avec les axes d'amélioration d'un algorithme naïf de K-Means. On constate bien qu'il est maintenant possible de caractériser des ensembles non convexes de points contrairement à un algorithme classique. On arrive à s'abstraire donc de la distance dans le plan de l'image pour analyser les propriétés des points et en tirer des ensembles plus cohérent. Dans un algorithme naïf par exemple, le cercle aurait au mieux donné un disque alors qu'ici nous obtenons bien un disque. Il en est de même pour les caractères qui comme dans l'article étudié auraient été séparés selon les distances spatiales.
	</p>
	<p>
		D'un point de vue plus pratique le programme manipule des données de taille très importante : si l'on considère une image de taille WxH alors notre programme manipulera des matrices de dimension (W*L) x (W*L). Concrètement, une image de taille moyenne 512x256 par exemple, comporte donc 131 072 pixels qui va générer une matrice d'affinité de taille 131072x131072 soit une matrice de plus de 17 milliard d'éléments et si on considère 3 octets par élément on manipulera donc des matrices de plus de 48Go. Malgré l'usage intensif de références et de suppressions de copies, les machines à notre disposition ne sont pas capables de traiter des données de cette taille raisonnablement, sans parler des dépassements de mémoire.
	</p>
	<p>
		C'est pourquoi nous avons travaillé sur des échantillons d'images de taille réduite. Il a donc aussi fallu revoir la taille des voisinages pour palier à la faible taille des images pour ne pas perdre trop d'information au calcul des paramètres des points.
	</p>
	<br/>
	<h1 class="titrearticle">Références</h1>
	<p>
		<ul class="references">
			<li id="biblio-1">[1] Andrew Y Ng, Michael I Jordan, and Yair Weiss. On Spectral Clustering: Analysis and an algorithm. Advances in Neural Information Processing Systems, pages 849-856, 2001.</li>
			<li id="biblio-2">[2] Charles J. Alpert , Andrew B. Kahng , So-Zen Yao, Spectral partitioning with multiple eigenvectors, Discrete Applied Mathematics, v.90 n.1-3, p.3-26, Jan. 15, 1999</li>
			<li id="biblio-3">[3] N. Christianini, J. Shawe-Taylor, and J. Kandola. Spectral kernel methods for clustering. In Neural Information Processing Systems 14, 2002.</li>
			<li id="biblio-4">[4] F. Chung. Spectral Graph Theory. Number 92 in CBMS Regional Conference Series in Mathematics. American Mathematical Society, 1997.</li>
			<li id="biblio-5">[5] R. Kannan , S. Vempala , A. Veta, On clusterings-good, bad and spectral, Proceedings of the 41st Annual Symposium on Foundations of Computer Science, p.367, November 12-14, 2000</li>
			<li id="biblio-6">[6] J. Malik, S. Belongie, T. Leung, and J. Shi. Contour and texture analysis for image segmentation. In Perceptual Organization for Artificial Vision Systems. Kluwcr, 2000,</li>
			<li id="biblio-7">[7] M. Meila and J. Shi. Learning segmentation by random walks. In Neural Information Processing Systems 13. 2001.</li>
			<li id="biblio-8">[8] Bernhard Schölkopf , Alexander Smola , Klaus-Robert Müller, Nonlinear component analysis as a kernel eigenvalue problem, Neural Computation, v.10 n.5, p.1299-1319, July 1, 1998</li>
			<li id="biblio-9">[9] G. Scott and H. Longuet-Higgins. Feature grouping by relocalisation of eigenvectors of the proximity matrix. In Proc. British Machine Vision Conference, 1990.</li>
			<li id="biblio-10">[10] D. A. Spielmat, Spectral partitioning works: planar graphs and finite element meshes, Proceedings of the 37th Annual Symposium on Foundations of Computer Science, p.96, October 14-16, 1996</li>
			<li id="biblio-11">[11] G. W. Stewart and J.-G. Sun. Matrix Perturbation Theory. Academic Press, 1990.</li>
			<li id="biblio-12">[12] Yair Weiss, Segmentation Using Eigenvectors: A Unifying View, Proceedings of the International Conference on Computer Vision-Volume 2, p.975, September 20-25, 1999</li>
		</ul>
	</p>
</body>
</html>
